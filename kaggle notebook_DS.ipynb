{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"!nvidia-smi\n","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:14:03.639964Z","iopub.execute_input":"2022-03-16T15:14:03.641073Z","iopub.status.idle":"2022-03-16T15:14:04.414610Z","shell.execute_reply.started":"2022-03-16T15:14:03.640933Z","shell.execute_reply":"2022-03-16T15:14:04.413855Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n!python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:15:04.171414Z","iopub.execute_input":"2022-03-16T15:15:04.171689Z","iopub.status.idle":"2022-03-16T15:16:09.034474Z","shell.execute_reply.started":"2022-03-16T15:15:04.171657Z","shell.execute_reply":"2022-03-16T15:16:09.033684Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import torch_xla\nimport torch_xla.core.xla_model as xm","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:33:13.224453Z","iopub.execute_input":"2022-03-16T15:33:13.225707Z","iopub.status.idle":"2022-03-16T15:33:13.980943Z","shell.execute_reply.started":"2022-03-16T15:33:13.225648Z","shell.execute_reply":"2022-03-16T15:33:13.979879Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#huggingface libraries \nimport transformers\nfrom transformers import BertTokenizer, BertForSequenceClassification\nfrom transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification\nfrom transformers import AdamW\n#torch\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, RandomSampler, SequentialSampler, Dataset, TensorDataset\n\n#random libraries\nfrom tqdm import tqdm \nimport pandas as pd\nimport numpy as np\nimport os\nimport gc\nimport random\n\n#  For setting a seed value\ntorch.manual_seed(555)\n\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import roc_auc_score, accuracy_score\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\nprint(torch.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:34:09.496236Z","iopub.execute_input":"2022-03-16T15:34:09.496783Z","iopub.status.idle":"2022-03-16T15:34:16.969635Z","shell.execute_reply.started":"2022-03-16T15:34:09.496742Z","shell.execute_reply":"2022-03-16T15:34:16.968716Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_data=pd.read_csv(\"/kaggle/input/contradictory-my-dear-watson/train.csv\")\ntest_data=pd.read_csv(\"/kaggle/input/contradictory-my-dear-watson/test.csv\")\n\ntrain_data","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:35:07.063469Z","iopub.execute_input":"2022-03-16T15:35:07.064345Z","iopub.status.idle":"2022-03-16T15:35:07.199740Z","shell.execute_reply.started":"2022-03-16T15:35:07.064301Z","shell.execute_reply":"2022-03-16T15:35:07.198844Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# PRE-PROCESSING THE DATA TYPE\n#model_name = 'bert-base-multilingual-uncased'\n#model_name = 'xlm-roberta-base'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = 'joeddav/xlm-roberta-large-xnli' \nbatch_size = 32\nMAX_LENGTH = 256\nNUM_EPOCHS = 3\nL_RATE = 1e-5\nNUM_CORES = os.cpu_count()\n\nNUM_CORES","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:38:33.120080Z","iopub.execute_input":"2022-03-16T15:38:33.120421Z","iopub.status.idle":"2022-03-16T15:38:33.127605Z","shell.execute_reply.started":"2022-03-16T15:38:33.120387Z","shell.execute_reply":"2022-03-16T15:38:33.126806Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"device = xm.xla_device()\n\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:38:52.102386Z","iopub.execute_input":"2022-03-16T15:38:52.102789Z","iopub.status.idle":"2022-03-16T15:38:57.390065Z","shell.execute_reply.started":"2022-03-16T15:38:52.102761Z","shell.execute_reply":"2022-03-16T15:38:57.389242Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"tokenizer=XLMRobertaTokenizer.from_pretrained(model_name, do_lower_case=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:39:15.374221Z","iopub.execute_input":"2022-03-16T15:39:15.374510Z","iopub.status.idle":"2022-03-16T15:39:18.005546Z","shell.execute_reply.started":"2022-03-16T15:39:15.374483Z","shell.execute_reply":"2022-03-16T15:39:18.004524Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# sample_data = list(zip(train_data['premise'][:2], train_data['hypothesis'][:2]))\n# print(sample_data)\n# tokenized_sample = tokenizer.batch_encode_plus(sample_data, **kwargs)\n# print(tokenized_sample)\ndef preprocess(data1, tokenizer):\n    kwargs = { 'truncation': True,\n    'max_length': MAX_LENGTH,\n    'padding': 'max_length',\n     'return_attention_mask': True, \n    'return_token_type_ids': True     \n    }\n    data = list(zip(data1['premise'], data1['hypothesis']))\n    tokenized = tokenizer.batch_encode_plus(data,**kwargs)\n    input_ids = torch.LongTensor(tokenized.input_ids)\n    attention_masks = torch.LongTensor(tokenized.attention_mask)\n    token_type_ids = torch.LongTensor(tokenized.token_type_ids)\n    return input_ids, attention_masks, token_type_ids","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:40:20.726955Z","iopub.execute_input":"2022-03-16T15:40:20.727302Z","iopub.status.idle":"2022-03-16T15:40:20.735003Z","shell.execute_reply.started":"2022-03-16T15:40:20.727269Z","shell.execute_reply":"2022-03-16T15:40:20.734143Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"input_ids, attention_masks, token_type_ids = preprocess(train_data,tokenizer)\nlabels = torch.Tensor(train_data['label']).reshape(-1, 1)\ntrain_dataset_final = TensorDataset(input_ids, attention_masks, token_type_ids,labels)\ntrain_dataloader = DataLoader(train_dataset_final, sampler=RandomSampler(train_dataset_final), batch_size=batch_size)\ntrain_dataset_final","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:43:00.669664Z","iopub.execute_input":"2022-03-16T15:43:00.669992Z","iopub.status.idle":"2022-03-16T15:43:04.765638Z","shell.execute_reply.started":"2022-03-16T15:43:00.669956Z","shell.execute_reply":"2022-03-16T15:43:04.764586Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(len(train_dataloader))\n","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:43:30.898827Z","iopub.execute_input":"2022-03-16T15:43:30.899159Z","iopub.status.idle":"2022-03-16T15:43:30.904619Z","shell.execute_reply.started":"2022-03-16T15:43:30.899124Z","shell.execute_reply":"2022-03-16T15:43:30.903784Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"input_ids_test, attention_masks_test, token_type_ids_test = preprocess(test_data,tokenizer)\ntest_dataset_final = TensorDataset(input_ids_test, attention_masks_test, token_type_ids_test)\ntest_dataloader = DataLoader(test_dataset_final, sampler=SequentialSampler(test_dataset_final), batch_size=batch_size)\nlen(test_dataloader)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:46:46.312401Z","iopub.execute_input":"2022-03-16T15:46:46.312727Z","iopub.status.idle":"2022-03-16T15:46:47.849791Z","shell.execute_reply.started":"2022-03-16T15:46:46.312694Z","shell.execute_reply":"2022-03-16T15:46:47.848891Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model = XLMRobertaForSequenceClassification.from_pretrained(model_name, num_labels=3)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:47:12.746123Z","iopub.execute_input":"2022-03-16T15:47:12.746612Z","iopub.status.idle":"2022-03-16T15:48:43.861659Z","shell.execute_reply.started":"2022-03-16T15:47:12.746565Z","shell.execute_reply":"2022-03-16T15:48:43.860756Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# TESTING MODEL","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch = next(iter(train_dataloader))\nb_input_ids = batch[0].to(device)\nb_input_mask = batch[1].to(device)\nb_token_type_ids = batch[2].to(device)\nb_labels = batch[3].to(device)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:49:53.797771Z","iopub.execute_input":"2022-03-16T15:49:53.798639Z","iopub.status.idle":"2022-03-16T15:49:53.848605Z","shell.execute_reply.started":"2022-03-16T15:49:53.798580Z","shell.execute_reply":"2022-03-16T15:49:53.847709Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"outputs = model(b_input_ids, \n                token_type_ids=b_token_type_ids, \n                attention_mask=b_input_mask,\n                labels=b_labels)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:50:12.456729Z","iopub.execute_input":"2022-03-16T15:50:12.457439Z","iopub.status.idle":"2022-03-16T15:50:12.561929Z","shell.execute_reply.started":"2022-03-16T15:50:12.457400Z","shell.execute_reply":"2022-03-16T15:50:12.561145Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"print(outputs[0])\nprint(outputs[0].item())","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:51:14.857248Z","iopub.execute_input":"2022-03-16T15:51:14.857540Z","iopub.status.idle":"2022-03-16T15:51:30.181731Z","shell.execute_reply.started":"2022-03-16T15:51:14.857513Z","shell.execute_reply":"2022-03-16T15:51:30.180707Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# TRAINING MODEL","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(),\n              lr = L_RATE, \n              eps = 1e-8\n            )","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:53:35.990852Z","iopub.execute_input":"2022-03-16T15:53:35.991202Z","iopub.status.idle":"2022-03-16T15:53:35.998031Z","shell.execute_reply.started":"2022-03-16T15:53:35.991156Z","shell.execute_reply":"2022-03-16T15:53:35.997284Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:54:11.542774Z","iopub.execute_input":"2022-03-16T15:54:11.543098Z","iopub.status.idle":"2022-03-16T15:54:11.852217Z","shell.execute_reply.started":"2022-03-16T15:54:11.543067Z","shell.execute_reply":"2022-03-16T15:54:11.851269Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"seed_val = 1024\n\nrandom.seed(seed_val)\nnp.random.seed(seed_val)\ntorch.manual_seed(seed_val)\ntorch.cuda.manual_seed_all(seed_val)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:54:34.963491Z","iopub.execute_input":"2022-03-16T15:54:34.963787Z","iopub.status.idle":"2022-03-16T15:54:34.971153Z","shell.execute_reply.started":"2022-03-16T15:54:34.963756Z","shell.execute_reply":"2022-03-16T15:54:34.970354Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"for epoch in range(NUM_EPOCHS):\n    model.train()\n    torch.set_grad_enabled(True)\n    total_train_loss=0\n    \n    for i,batch in tqdm(enumerate(train_dataloader)):\n        model.zero_grad()\n        input_ids, attention_masks, token_type_ids, labels=batch[0].to(device), batch[1].to(device), batch[2].to(device), batch[3].to(device)\n        outputs = model(input_ids, token_type_ids=token_type_ids, attention_mask=attention_masks, labels=labels)\n        loss=outputs[0]\n        if i%10==0:\n            print(f'loss of batch {i}: {loss}')\n        total_train_loss+=loss.item()\n        optimizer.zero_grad()\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(),1.0)\n        xm.optimizer_step(optimizer, barrier=True) \n    print(f'total loss of epoch {epoch}: {total_train_loss}')\n    gc.collect()    \n","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:55:11.254864Z","iopub.execute_input":"2022-03-16T15:55:11.255182Z","iopub.status.idle":"2022-03-16T16:28:08.057531Z","shell.execute_reply.started":"2022-03-16T15:55:11.255134Z","shell.execute_reply":"2022-03-16T16:28:08.056587Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"stacked_val_labels = []\nmodel.eval()\n\ntorch.set_grad_enabled(False)\ntotal_val_loss = 0\n\nfor j, h_batch in enumerate(test_dataloader):\n\n    b_input_ids = h_batch[0].to(device)\n    b_input_mask = h_batch[1].to(device)\n    b_token_type_ids = h_batch[2].to(device)     \n    outputs = model(b_input_ids, \n            token_type_ids=b_token_type_ids, \n            attention_mask=b_input_mask)\n    preds = outputs[0]\n    val_preds = preds.detach().cpu().numpy()\n    if j == 0:  # first batch\n        stacked_val_preds = val_preds\n        \n    else:\n        stacked_val_preds = np.vstack((stacked_val_preds, val_preds))\n        #stacked_val_preds.extend(val_preds)\n    #print(len(stacked_val_preds))\n    \n            \nprint('\\nPrediction complete.')","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:29:51.544031Z","iopub.execute_input":"2022-03-16T16:29:51.544354Z","iopub.status.idle":"2022-03-16T16:30:43.269332Z","shell.execute_reply.started":"2022-03-16T16:29:51.544322Z","shell.execute_reply":"2022-03-16T16:30:43.268291Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"print(stacked_val_preds)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:31:03.708647Z","iopub.execute_input":"2022-03-16T16:31:03.708970Z","iopub.status.idle":"2022-03-16T16:31:03.716686Z","shell.execute_reply.started":"2022-03-16T16:31:03.708937Z","shell.execute_reply":"2022-03-16T16:31:03.715440Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"test_preds = np.argmax(stacked_val_preds, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:32:25.457461Z","iopub.execute_input":"2022-03-16T16:32:25.458395Z","iopub.status.idle":"2022-03-16T16:32:25.462872Z","shell.execute_reply.started":"2022-03-16T16:32:25.458349Z","shell.execute_reply":"2022-03-16T16:32:25.462095Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"path = '../input/contradictory-my-dear-watson/sample_submission.csv'\n\ndf_sample = pd.read_csv(path)\n\nprint(df_sample.shape)\ndf_sample['prediction'] = test_preds\n\ndf_sample.head()\ndf_sample.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:32:42.745542Z","iopub.execute_input":"2022-03-16T16:32:42.745858Z","iopub.status.idle":"2022-03-16T16:32:42.791280Z","shell.execute_reply.started":"2022-03-16T16:32:42.745827Z","shell.execute_reply":"2022-03-16T16:32:42.790129Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}